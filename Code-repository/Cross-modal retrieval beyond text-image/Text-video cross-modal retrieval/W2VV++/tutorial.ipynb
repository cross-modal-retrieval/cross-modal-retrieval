{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial code for W2VV++ based sentence and video embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from model import get_model\n",
    "from bigfile import BigFile\n",
    "from evaluation import compute_sim\n",
    "from common import ROOT_PATH as rootpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint to initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loaded checkpoint '/data/home/xcx/VisualSearch/w2vvpp/w2vvpp_resnext101_resnet152_subspace_v190916.pth.tar' (best_perf 0.55695818775)\n",
      "VisTransformNet(\n",
      "  (fc1): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (activation): Tanh()\n",
      "  (dropout): Dropout(p=0.2)\n",
      ")\n",
      "MultiScaleTxtNet(\n",
      "  (encoder): MultiScaleTxtEncoder(\n",
      "    (rnn_encoder): GruTxtEncoder(\n",
      "      (we): Embedding(11286, 500)\n",
      "      (rnn): GRU(500, 1024, batch_first=True)\n",
      "    )\n",
      "    (w2v_encoder): W2VTxtEncoder()\n",
      "    (bow_encoder): BoWTxtEncoder()\n",
      "  )\n",
      "  (transformer): TxtTransformNet(\n",
      "    (fc1): Linear(in_features=12671, out_features=2048, bias=True)\n",
      "    (activation): Tanh()\n",
      "    (dropout): Dropout(p=0.2)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(rootpath, 'w2vvpp', 'w2vvpp_resnext101_resnet152_subspace_v190916.pth.tar')\n",
    "if torch.cuda.is_available():\n",
    "    checkpoint = torch.load(model_path)\n",
    "else:\n",
    "    checkpoint = torch.load(model_path,map_location='cpu')\n",
    "best_perf = checkpoint['best_perf']\n",
    "config = checkpoint['config']\n",
    "if hasattr(config, 't2v_w2v'):\n",
    "    w2v_feature_file = os.path.join(rootpath, 'word2vec', 'flickr', 'vec500flickr30m', 'feature.bin')\n",
    "    config.t2v_w2v.w2v.binary_file = w2v_feature_file\n",
    "\n",
    "model = get_model('w2vvpp')(config)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "print(\"=> loaded checkpoint '{}' (best_perf {})\"\n",
    "      .format(model_path, best_perf))\n",
    "\n",
    "print(model.vis_net)\n",
    "print(model.txt_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed video feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BigFile] 200x4096 instances loaded from /data/home/xcx/VisualSearch/tv2016train/FeatureData/mean_resnext101_resnet152\n"
     ]
    }
   ],
   "source": [
    "# load video feature\n",
    "video_collection = 'tv2016train'\n",
    "feat_name = 'mean_resnext101_resnet152'\n",
    "vid_feat_dir = os.path.join(rootpath, video_collection, 'FeatureData', feat_name)\n",
    "vid_feat_file = BigFile(vid_feat_dir)\n",
    "\n",
    "videoset = vid_feat_file.names\n",
    "renamed, vectors = vid_feat_file.read(videoset)\n",
    "nr_videos = len(renamed)\n",
    "vis_vecs = np.array([model.embed_vis(x)[0].numpy() for x in vectors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'a dog is playing with a cat'\n",
    "sent_vec = model.embed_txt(sent).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute text2video similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_sim execution time: 0.036 seconds\n",
      "\n",
      "[('tv2016train_video92', 0.43230182), ('tv2016train_video147', 0.38227573), ('tv2016train_video128', 0.3500569), ('tv2016train_video14', 0.28239024), ('tv2016train_video195', 0.27338427)]\n"
     ]
    }
   ],
   "source": [
    "ranklist = [(renamed[i], sim) for i, sim in enumerate(compute_sim(sent_vec, vis_vecs, measure='cosine')[0])]\n",
    "ranklist.sort(key=lambda v:v[1], reverse=True)\n",
    "\n",
    "print (ranklist[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_file = os.path.join(rootpath, video_collection, 'TextData', video_collection+'.caption.txt')\n",
    "sentences = [line.strip().split(' ', 1)[1] for line in open(caption_file)]\n",
    "sent_vecs = np.array([model.embed_txt(sent)[0].numpy() for sent in sentences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute text2text similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_sim execution time: 0.013 seconds\n",
      "\n",
      "query: a man lying on a bed\n",
      "\n",
      "a man lying on a bed 1.000000\n",
      "a person is lying on a bed 0.921146\n",
      "A woman cries on a bed 0.626783\n",
      "A man makes noises in front of a bed 0.584935\n",
      "a man sitting in a car 0.417096\n"
     ]
    }
   ],
   "source": [
    "qry_idx = random.randint(0, len(sentences)-1)\n",
    "qry_sent_vec = np.array([sent_vecs[qry_idx]])\n",
    "\n",
    "ranklist = [(sentences[i], sim) for i, sim in enumerate(compute_sim(qry_sent_vec, sent_vecs, measure='cosine')[0])]\n",
    "ranklist.sort(key=lambda v:v[1], reverse=True)\n",
    "\n",
    "print 'query: %s\\n' % sentences[qry_idx]\n",
    "print '\\n'.join(['%s %f'%(x[0], x[1]) for x in ranklist[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
