# Welcome to our toolbox for cross-modal retrievalÔºÅ üëãüëãüëã

Our platform provides implementations of representative cross-modal retrieval methods, 
offering a comprehensive resource for researchers to experiment with and compare different approaches. 
By presenting these tools in an accessible format, we aim to streamline the process of experimental validation and performance evaluation. 

# Introduction
In this toolbox, we have integrated some representative cross-modal retrieval methods. Since these methods utilize different programming languages (such as Matlab and Python), development frameworks (such as TensorFlow and Torch), and diverse dependencies, we have organized them into three main environments:  
1) **Matlab**, to support all shallow cross-modal retrieval methods;  
2) **TensorFlow**, to support some deep cross-modal retrieval methods;  
3) **Torch**, to support some deep cross-modal retrieval methods.

Once the toolbox and datasets are stored and the above environments is set up, you can invoke the integrated cross-modal retrieval methods by running the `train.sh` file within the toolbox.


# Instruction
Below, we showcase how to use the cross-modal retrieval toolbox we developed.

## Install the toolbox


## Download datasets


## Configure environments


## Use the toolbox


## Note
Our toolbox is still in its initial version, and more cross-modal retrieval methods are continuously being added. If you have any questions, please feel free to leave us a message!

# Cite our paper
    <div class="container is-max-widescreen content">
        <h2 class="title">BibTeX</h2>
        <pre><code>
@article{li2023cross,
      title={Cross-modal retrieval: a systematic review of methods and future directions},
      author={Li, Fengling and Zhu, Lei and Wang, Tianshi and Li, Jingjing and Zhang, Zheng and Shen, Heng Tao},
      journal={arXiv preprint arXiv:2308.14263},
      year={2023}
      }
        </code></pre>
    </div>
