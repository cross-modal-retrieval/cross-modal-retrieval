# Welcome to our toolbox for cross-modal retrievalï¼ ğŸ‘‹ğŸ‘‹ğŸ‘‹

Our platform provides implementations of representative cross-modal retrieval methods, 
offering a comprehensive resource for researchers to experiment with and compare different approaches. 
By presenting these tools in an accessible format, we aim to streamline the process of experimental validation and performance evaluation. 

# Introduction
In this toolbox, we have integrated some representative cross-modal retrieval methods. Since these methods utilize different programming languages (such as Matlab and Python), development frameworks (such as TensorFlow and Torch), and diverse dependencies, we have organized them into three main environments:  
1) **Matlab**, to support all shallow cross-modal retrieval methods;  
2) **TensorFlow**, to support some deep cross-modal retrieval methods;  
3) **Torch**, to support some deep cross-modal retrieval methods.

Once the toolbox and datasets are stored and the above environments is set up, you can invoke the integrated cross-modal retrieval methods by running the `train.sh` file within the toolbox.


# Instruction
Below, we showcase how to use the cross-modal retrieval toolbox we developed.

## Install the toolbox


## Download datasets


## 
